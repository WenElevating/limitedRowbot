#!/usr/bin/env node
import { Command } from 'commander';
import { config } from 'dotenv';
import chalk from 'chalk';
import { homedir } from 'os';
import { join } from 'path';
import { existsSync, mkdirSync, readFileSync, writeFileSync } from 'fs';
import { TerminalUI } from '@robot/cli-ui';
import { createOpenAIProvider, createGlmProvider, GLM_MODELS, type LLMProvider } from '@robot/llm-adapter';
import { createSemanticRouter } from '@robot/intent-router';
import { createShellAdapter } from '@robot/windows-adapter';
import { createToolService, type ToolService } from './tool-service.js';

config();

const CONFIG_DIR = join(homedir(), '.robot');
const CONFIG_FILE = join(CONFIG_DIR, 'config.json');

interface AppConfig {
  provider: string;
  model: string;
  apiKey?: string;
  baseUrl?: string;
}

interface AppContext {
  llmProvider: LLMProvider;
  config: AppConfig;
  chatHistory: { role: 'user' | 'assistant' | 'system'; content: string }[];
  toolService?: ToolService;
  setProvider: (provider: LLMProvider, config: AppConfig) => void;
}

function loadConfig(): AppConfig | null {
  if (!existsSync(CONFIG_FILE)) return null;
  try {
    const content = readFileSync(CONFIG_FILE, 'utf-8');
    return JSON.parse(content);
  } catch {
    return null;
  }
}

function saveConfig(cfg: AppConfig): void {
  if (!existsSync(CONFIG_DIR)) {
    mkdirSync(CONFIG_DIR, { recursive: true });
  }
  writeFileSync(CONFIG_FILE, JSON.stringify(cfg, null, 2));
}

async function createProvider(cfg: AppConfig): Promise<LLMProvider> {
  if (cfg.provider === 'glm') {
    return createGlmProvider({
      model: cfg.model,
      apiKey: cfg.apiKey || process.env.GLM_API_KEY || '',
      baseUrl: cfg.baseUrl,
    });
  }
  return createOpenAIProvider({
    model: cfg.model,
    apiKey: cfg.apiKey || process.env.OPENAI_API_KEY || '',
    baseUrl: cfg.baseUrl,
  });
}

async function initContext(): Promise<AppContext> {
  let cfg = loadConfig();
  
  if (!cfg) {
    cfg = {
      provider: 'glm',
      model: 'glm-4-flash',
      apiKey: process.env.GLM_API_KEY || '',
      baseUrl: process.env.GLM_BASE_URL,
    };
    saveConfig(cfg);
  }

  const llmProvider = await createProvider(cfg);

  let currentProvider = llmProvider;
  let currentConfig = cfg;

  return {
    get llmProvider() { return currentProvider; },
    get config() { return currentConfig; },
    chatHistory: [],
    setProvider: (provider: LLMProvider, config: AppConfig) => {
      currentProvider = provider;
      currentConfig = config;
    },
  };
}

const SYSTEM_PROMPT = `ä½ æ˜¯ä¸€ä¸ªé«˜æ•ˆã€å‡†ç¡®ã€æé€Ÿå“åº”çš„ CLI åŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š

1. **ç†è§£æ„å›¾**ï¼šå¿«é€Ÿè¯†åˆ«ç”¨æˆ·è¯·æ±‚ç±»å‹ï¼ŒåŒ…æ‹¬ç³»ç»Ÿä»»åŠ¡ã€çŸ¥è¯†é—®ç­”ã€å¤©æ°”æŸ¥è¯¢ã€æ–‡æ¡£æ£€ç´¢ç­‰ã€‚
2. **å“åº”é€‚ä¸­**ï¼šå›ç­”è¦ç®€æ´ä½†å®Œæ•´ï¼Œä¸è¦è¿‡äºç®€çŸ­å¯¼è‡´ä¿¡æ¯ä¸è¶³ï¼Œä¹Ÿä¸è¦è¿‡äºå†—é•¿ã€‚ç»“æ„åŒ–è¾“å‡ºï¼Œä½¿ç”¨åˆ—è¡¨å’Œåˆ†ç±»è®©ä¿¡æ¯æ¸…æ™°ã€‚
3. **ç›´æ¥æ‰§è¡Œ/å›ç­”**ï¼š
   - ç³»ç»Ÿä»»åŠ¡ï¼ˆCPUã€å†…å­˜ã€ç£ç›˜ã€æ–‡ä»¶ã€è¿›ç¨‹ï¼‰ â†’ ç›´æ¥ç”Ÿæˆå¯æ‰§è¡Œå‘½ä»¤æˆ–æ“ä½œå»ºè®®ã€‚
   - é—®ç­”ã€çŸ¥è¯†æŸ¥è¯¢ â†’ ä½¿ç”¨æœ€æ–°æ–‡æ¡£ / MCP / ç½‘ç»œèµ„æºå›ç­”ï¼Œç›´æ¥ç»™å‡ºç»“è®ºã€‚
   - å¤©æ°”ã€æ—¶é—´ç­‰åŠ¨æ€ä¿¡æ¯ â†’ è¿”å›å‡†ç¡®çš„å®æ—¶ç»“æœã€‚
4. **è¾“å‡ºç»“æ„åŒ–**ï¼š
   - å¿…è¦æ—¶åŒºåˆ†ï¼š
     - å‘½ä»¤: <æ‰§è¡Œå‘½ä»¤>
     - è¾“å‡º: <ç»“æœæ‘˜è¦>
     - æ€»ç»“: <æ ¸å¿ƒç»“è®º>
   - ä½¿ç”¨åˆ†ç±»å’Œåˆ—è¡¨ç»„ç»‡ä¿¡æ¯ï¼Œè®©å†…å®¹æ˜“è¯»ã€‚
5. **ä¸­æ–‡ä¼˜å…ˆ**ï¼šé»˜è®¤ä½¿ç”¨ä¸­æ–‡ï¼Œç®€æ˜æ‰¼è¦ã€‚
6. **é¿å…åºŸè¯**ï¼šä¸è¦é‡å¤ç”¨æˆ·è¾“å…¥ï¼Œä¸è¾“å‡ºæ— å…³èƒŒæ™¯ä¿¡æ¯ã€‚
7. **å®‰å…¨ä¸ç¡®è®¤**ï¼šæ¶‰åŠç ´åæ€§æ“ä½œï¼ˆåˆ é™¤æ–‡ä»¶ã€ç»ˆæ­¢è¿›ç¨‹ç­‰ï¼‰å¿…é¡»ç¡®è®¤ç”¨æˆ·æ„å›¾ã€‚
8. **å¿«é€Ÿå†³ç­–**ï¼š
   - ä¸åšå†—é•¿åˆ†æï¼Œç›´æ¥ç»™å‡ºå¯æ“ä½œå†…å®¹æˆ–å‡†ç¡®ç­”æ¡ˆã€‚
   - å¦‚æœä¿¡æ¯ä¸å®Œæ•´ï¼Œå¯ç®€çŸ­æç¤ºè¡¥å……ã€‚
9. **å¼•ç”¨æœ€æ–°ä¿¡æ¯**ï¼š
   - å¦‚æœæœ‰å¯ç”¨ MCPï¼ˆå¦‚ Context7 æˆ–ç½‘é¡µæŠ“å–ï¼‰ï¼Œä¼˜å…ˆä½¿ç”¨æœ€æ–°æ–‡æ¡£/æ•°æ®ã€‚
   - è¾“å‡ºå¿…é¡»ä¿è¯ä¿¡æ¯æœ€æ–°ã€å‡†ç¡®ã€‚`;

function getIntentAcknowledgment(input: string): string {
  const lowerInput = input.toLowerCase();
  
  if (lowerInput.includes('è§„åˆ’') || lowerInput.includes('æ–¹æ¡ˆ') || lowerInput.includes('è®¡åˆ’')) {
    return 'æˆ‘æ¥å¸®ä½ è§„åˆ’ä¸€ä¸ªæ–¹æ¡ˆï¼';
  }
  if (lowerInput.includes('cpu')) {
    return 'æˆ‘æ¥æ£€æŸ¥ CPU å ç”¨æƒ…å†µ...';
  }
  if (lowerInput.includes('å†…å­˜') || lowerInput.includes('memory')) {
    return 'æˆ‘æ¥æ£€æŸ¥å†…å­˜å ç”¨æƒ…å†µ...';
  }
  if (lowerInput.includes('ç£ç›˜') || lowerInput.includes('disk')) {
    return 'æˆ‘æ¥æ£€æŸ¥ç£ç›˜ä½¿ç”¨æƒ…å†µ...';
  }
  if (lowerInput.includes('å¤©æ°”')) {
    return 'æˆ‘æ¥æŸ¥è¯¢å¤©æ°”ä¿¡æ¯...';
  }
  if (lowerInput.includes('æ¨è') || lowerInput.includes('å¥½ç©') || lowerInput.includes('æ™¯ç‚¹')) {
    return 'æˆ‘æ¥å¸®ä½ æœç´¢ç›¸å…³ä¿¡æ¯...';
  }
  
  return 'æˆ‘æ¥å¤„ç†ä½ çš„è¯·æ±‚...';
}

function detectTaskType(input: string): 'system' | 'search' | 'general' {
  const lowerInput = input.toLowerCase();
  
  if (lowerInput.includes('cpu') || lowerInput.includes('å†…å­˜') || lowerInput.includes('memory') || 
      lowerInput.includes('ç£ç›˜') || lowerInput.includes('disk') || lowerInput.includes('è¿›ç¨‹')) {
    return 'system';
  }
  
  if (lowerInput.includes('è§„åˆ’') || lowerInput.includes('æ–¹æ¡ˆ') || lowerInput.includes('æ¨è') ||
      lowerInput.includes('æ™¯ç‚¹') || lowerInput.includes('å¥½ç©') || lowerInput.includes('æ”»ç•¥')) {
    return 'search';
  }
  
  return 'general';
}

function trimHistory(history: { role: 'user' | 'assistant' | 'system'; content: string }[]): { role: 'user' | 'assistant' | 'system'; content: string }[] {
  if (history.length <= 6) return history;
  return history.slice(-6);
}

async function executeSystemTask(input: string, ctx: AppContext, ui: TerminalUI): Promise<void> {
  const shellAdapter = createShellAdapter();
  let command = '';
  let result;
  
  const lowerInput = input.toLowerCase();
  
  if (lowerInput.includes('cpu')) {
    ui.showStep('æ‰§è¡Œå‘½ä»¤', ' - æŸ¥è¯¢ CPU å ç”¨');
    command = 'Get-Process | Sort-Object CPU -Descending | Select-Object -First 5';
    result = await shellAdapter.executePowerShell(
      'Get-Process | Sort-Object CPU -Descending | Select-Object -First 5 Name, @{N="CPU(s)";E={$_.CPU.ToString("F2")}}, @{N="Memory(MB)";E={$_.WorkingSet64/1MB.ToString("F2")}} | Format-Table -AutoSize'
    );
  } else if (lowerInput.includes('å†…å­˜') || lowerInput.includes('memory')) {
    ui.showStep('æ‰§è¡Œå‘½ä»¤', ' - æŸ¥è¯¢å†…å­˜å ç”¨');
    command = 'Get-Process | Sort-Object WorkingSet64 -Descending | Select-Object -First 5';
    result = await shellAdapter.executePowerShell(
      'Get-Process | Sort-Object WorkingSet64 -Descending | Select-Object -First 5 Name, @{N="Memory(MB)";E={$_.WorkingSet64/1MB.ToString("F2")}}, @{N="CPU(s)";E={$_.CPU.ToString("F2")}} | Format-Table -AutoSize'
    );
  } else if (lowerInput.includes('ç£ç›˜') || lowerInput.includes('disk')) {
    ui.showStep('æ‰§è¡Œå‘½ä»¤', ' - æŸ¥è¯¢ç£ç›˜ä½¿ç”¨');
    command = 'Get-PSDrive -PSProvider FileSystem';
    result = await shellAdapter.executePowerShell(
      'Get-PSDrive -PSProvider FileSystem | Select-Object Name, @{N="Used(GB)";E={$_.Used/1GB.ToString("F2")}}, @{N="Free(GB)";E={$_.Free/1GB.ToString("F2")}} | Format-Table -AutoSize'
    );
  } else {
    ui.showStep('æ‰§è¡Œå‘½ä»¤', ' - æŸ¥è¯¢è¿›ç¨‹ä¿¡æ¯');
    command = 'Get-Process | Select-Object -First 10';
    result = await shellAdapter.executePowerShell(
      'Get-Process | Select-Object -First 10 Name, Id, CPU, @{N="Memory(MB)";E={$_.WorkingSet64/1MB.ToString("F2")}} | Format-Table -AutoSize'
    );
  }
  
  const output = result.stdout || result.stderr;
  ui.showStepResult(output.slice(0, 300) + (output.length > 300 ? '...' : ''));
  
  ui.showStreamingStatus('åˆ†æç»“æœ', ' - ç”Ÿæˆæ€»ç»“...');
  
  const messages = [
    { role: 'system' as const, content: SYSTEM_PROMPT },
    { role: 'user' as const, content: `ç”¨æˆ·é—®é¢˜: ${input}\n\næ‰§è¡Œç»“æœ:\n${output}\n\nè¯·ç”¨2-3å¥è¯ç®€æ´æ€»ç»“ã€‚` },
  ];
  
  if (ctx.llmProvider.stream) {
    ui.showStreamingStatus('ç”Ÿæˆä¸­', '...');
    ui.addTokens(0);
    
    let fullContent = '';
    let tokenCount = 0;
    let started = false;
    
    for await (const chunk of ctx.llmProvider.stream(messages)) {
      if (chunk.delta.content) {
        if (!started) {
          started = true;
          ui.hideThinking();
          ui.startStreaming();
        }
        fullContent += chunk.delta.content;
        tokenCount = Math.ceil(fullContent.length / 2);
        ui.addTokens(tokenCount);
        ui.streamChunk(chunk.delta.content);
      }
    }
    
    ui.stopStreaming();
    ctx.chatHistory.push({ role: 'user', content: input });
    ctx.chatHistory.push({ role: 'assistant', content: fullContent });
  } else {
    const response = await ctx.llmProvider.complete(messages);
    ui.hideThinking();
    if (response.usage) {
      ui.addTokens(response.usage.totalTokens);
    }
    ui.addAssistantMessage(response.message.content);
    ctx.chatHistory.push({ role: 'user', content: input });
    ctx.chatHistory.push({ role: 'assistant', content: response.message.content });
  }
}

async function executeSearchTask(input: string, ctx: AppContext, ui: TerminalUI): Promise<void> {
  ui.showStep('Search', `(${input.slice(0, 30)}${input.length > 30 ? '...' : ''})`);
  
  ui.showStreamingStatus('æœç´¢ä¸­', '...');
  
  const messages: { role: 'system' | 'user' | 'assistant'; content: string }[] = [
    { role: 'system', content: SYSTEM_PROMPT },
    ...trimHistory(ctx.chatHistory),
    { role: 'user', content: input },
  ];
  
  if (ctx.llmProvider.stream) {
    ui.showStreamingStatus('ç”Ÿæˆä¸­', '...');
    ui.addTokens(0);
    
    let fullContent = '';
    let tokenCount = 0;
    let started = false;
    
    for await (const chunk of ctx.llmProvider.stream(messages)) {
      if (chunk.delta.content) {
        if (!started) {
          started = true;
          ui.hideThinking();
          ui.showStepResult(`Found results for "${input.slice(0, 30)}..."`);
          ui.startStreaming();
        }
        fullContent += chunk.delta.content;
        tokenCount = Math.ceil(fullContent.length / 2);
        ui.addTokens(tokenCount);
        ui.streamChunk(chunk.delta.content);
      }
    }
    
    ui.stopStreaming();
    ctx.chatHistory.push({ role: 'user', content: input });
    ctx.chatHistory.push({ role: 'assistant', content: fullContent });
  } else {
    const response = await ctx.llmProvider.complete(messages);
    ui.hideThinking();
    ui.showStepResult(`Found results for "${input.slice(0, 30)}..."`);
    if (response.usage) {
      ui.addTokens(response.usage.totalTokens);
    }
    ui.addAssistantMessage(response.message.content);
    ctx.chatHistory.push({ role: 'user', content: input });
    ctx.chatHistory.push({ role: 'assistant', content: response.message.content });
  }
}

async function executeGeneralTask(input: string, ctx: AppContext, ui: TerminalUI): Promise<void> {
  if (ctx.chatHistory.length === 0) {
    ctx.chatHistory.push({ role: 'system', content: SYSTEM_PROMPT });
  }
  
  const messages: { role: 'system' | 'user' | 'assistant'; content: string }[] = [
    ...trimHistory(ctx.chatHistory),
    { role: 'user', content: input },
  ];
  
  if (ctx.llmProvider.stream) {
    ui.showStreamingStatus('æ€è€ƒä¸­', '...');
    ui.addTokens(0);
    
    let fullContent = '';
    let tokenCount = 0;
    let started = false;
    
    for await (const chunk of ctx.llmProvider.stream(messages)) {
      if (chunk.delta.content) {
        if (!started) {
          started = true;
          ui.hideThinking();
          ui.startStreaming();
        }
        fullContent += chunk.delta.content;
        tokenCount = Math.ceil(fullContent.length / 2);
        ui.addTokens(tokenCount);
        ui.streamChunk(chunk.delta.content);
      }
    }
    
    ui.stopStreaming();
    ctx.chatHistory.push({ role: 'user', content: input });
    ctx.chatHistory.push({ role: 'assistant', content: fullContent });
    ctx.chatHistory = trimHistory(ctx.chatHistory);
  } else {
    ui.showStreamingStatus('æ€è€ƒä¸­', '...');
    const response = await ctx.llmProvider.complete(messages);
    ui.hideThinking();
    if (response.usage) {
      ui.addTokens(response.usage.totalTokens);
    }
    ui.addAssistantMessage(response.message.content);
    ctx.chatHistory.push({ role: 'user', content: input });
    ctx.chatHistory.push({ role: 'assistant', content: response.message.content });
  }
}

const BUILTIN_COMMANDS: Record<string, string> = {
  '/help': `å¯ç”¨å‘½ä»¤ï¼š
  /help     - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
  /clear    - æ¸…ç©ºå¯¹è¯å†å²
  /exit     - é€€å‡ºç¨‹åº
  /config   - æ˜¾ç¤º/ä¿®æ”¹é…ç½®
  /model    - æ˜¾ç¤ºå¯ç”¨æ¨¡å‹åˆ—è¡¨
  /model <name> - åˆ‡æ¢åˆ°æŒ‡å®šæ¨¡å‹
  /mcp      - MCP å·¥å…·ï¼ˆå¼€å‘ä¸­ï¼‰
  /weather  - å¤©æ°”æŸ¥è¯¢ï¼ˆå¼€å‘ä¸­ï¼‰
  /search   - æœç´¢åŠŸèƒ½ï¼ˆå¼€å‘ä¸­ï¼‰
  
ç›´æ¥è¾“å…¥é—®é¢˜å³å¯ä¸æˆ‘å¯¹è¯ï¼`,
  '/clear': 'å¯¹è¯å†å²å·²æ¸…ç©ºã€‚',
  '/exit': 'å†è§ï¼',
  '/config': '',
  '/model': '',
  '/mcp': 'MCP å·¥å…·åŠŸèƒ½å¼€å‘ä¸­...',
  '/weather': 'å¤©æ°”æŸ¥è¯¢åŠŸèƒ½å¼€å‘ä¸­...',
  '/search': 'æœç´¢åŠŸèƒ½å¼€å‘ä¸­...',
};

function isBuiltinCommand(input: string): string | null {
  const parts = input.trim().toLowerCase().split(/\s+/);
  const cmd = parts[0];
  if (cmd && cmd in BUILTIN_COMMANDS) {
    return cmd;
  }
  return null;
}

async function processInput(input: string, ctx: AppContext, ui: TerminalUI): Promise<void> {
  const builtinCmd = isBuiltinCommand(input);
  
  if (builtinCmd) {
    const args = input.trim().split(/\s+/).slice(1);
    
    switch (builtinCmd) {
      case '/help':
        ui.showStep('æ˜¾ç¤ºå¸®åŠ©');
        ui.showStepResult(BUILTIN_COMMANDS['/help']!);
        ui.showStepDone();
        break;
      case '/clear':
        ctx.chatHistory.length = 0;
        ui.showStep('æ¸…ç©ºå†å²');
        ui.showStepResult(BUILTIN_COMMANDS['/clear']!);
        ui.showStepDone();
        break;
      case '/exit':
        ui.showStep('é€€å‡º');
        ui.showStepResult(BUILTIN_COMMANDS['/exit']!);
        setTimeout(() => process.exit(0), 500);
        break;
      case '/config':
        const configItems = [
          `Provider: ${ctx.config.provider}`,
          `Model: ${ctx.config.model}`,
          `API Key: ${ctx.config.apiKey ? '********' : '(æœªè®¾ç½®)'}`,
          `Base URL: ${ctx.config.baseUrl || '(é»˜è®¤)'}`,
        ];
        
        ui.showListSelect(
          'é€‰æ‹©è¦ä¿®æ”¹çš„é…ç½®é¡¹',
          configItems,
          async (index) => {
            const keys = ['provider', 'model', 'apiKey', 'baseUrl'] as const;
            const key = keys[index];
            const keyNames = ['Provider', 'Model', 'API Key', 'Base URL'];
            
            if (key === 'model' && ctx.config.provider === 'glm') {
              ui.showListSelect(
                'é€‰æ‹©æ¨¡å‹',
                [...GLM_MODELS],
                async (modelIndex) => {
                  const modelName = GLM_MODELS[modelIndex] ?? 'glm-4-flash';
                  const newConfig: AppConfig = { ...ctx.config, model: modelName };
                  saveConfig(newConfig);
                  const newProvider = await createProvider(newConfig);
                  ctx.setProvider(newProvider, newConfig);
                  ui.setConfig(newConfig.provider, newConfig.model);
                  ui.showStep('é…ç½®å·²æ›´æ–°');
                  ui.showStepResult(`Model å·²åˆ‡æ¢ä¸º: ${modelName}`);
                  ui.showStepDone();
                },
                () => {
                  ui.showStep('å·²å–æ¶ˆ');
                  ui.showStepDone();
                }
              );
            } else {
              ui.showInputPrompt(
                `ä¿®æ”¹ ${keyNames[index]}`,
                async (value) => {
                  if (value.trim()) {
                    let newConfig: AppConfig;
                    if (key === 'provider') {
                      newConfig = { ...ctx.config, provider: value.trim() };
                    } else if (key === 'model') {
                      newConfig = { ...ctx.config, model: value.trim() };
                    } else if (key === 'apiKey') {
                      newConfig = { ...ctx.config, apiKey: value.trim() };
                    } else {
                      newConfig = { ...ctx.config, baseUrl: value.trim() };
                    }
                    saveConfig(newConfig);
                    const newProvider = await createProvider(newConfig);
                    ctx.setProvider(newProvider, newConfig);
                    ui.setConfig(newConfig.provider, newConfig.model);
                    ui.showStep('é…ç½®å·²æ›´æ–°');
                    ui.showStepResult(`${keyNames[index]} å·²æ›´æ–°`);
                    ui.showStepDone();
                  } else {
                    ui.showStep('å·²å–æ¶ˆ');
                    ui.showStepResult('é…ç½®æœªä¿®æ”¹');
                    ui.showStepDone();
                  }
                },
                () => {
                  ui.showStep('å·²å–æ¶ˆ');
                  ui.showStepDone();
                }
              );
            }
          },
          () => {
            ui.showStep('å·²å–æ¶ˆ');
            ui.showStepDone();
          }
        );
        break;
      case '/model':
        if (ctx.config.provider === 'glm') {
          ui.showListSelect(
            'é€‰æ‹©æ¨¡å‹',
            [...GLM_MODELS],
            async (modelIndex) => {
              const modelName = GLM_MODELS[modelIndex] ?? 'glm-4-flash';
              const newConfig: AppConfig = { ...ctx.config, model: modelName };
              saveConfig(newConfig);
              const newProvider = await createProvider(newConfig);
              ctx.setProvider(newProvider, newConfig);
              ui.setConfig(newConfig.provider, newConfig.model);
              ui.showStep('æ¨¡å‹å·²åˆ‡æ¢');
              ui.showStepResult(`å½“å‰æ¨¡å‹: ${modelName}`);
              ui.showStepDone();
            },
            () => {
              ui.showStep('å·²å–æ¶ˆ');
              ui.showStepDone();
            }
          );
        } else {
          ui.showStep('å¯ç”¨æ¨¡å‹');
          ui.showStepResult(`å½“å‰ Provider: ${ctx.config.provider}\nå½“å‰æ¨¡å‹: ${ctx.config.model}`);
          ui.showStepDone();
        }
        break;
      case '/mcp':
      case '/weather':
      case '/search':
        ui.showStep(builtinCmd.slice(1).toUpperCase());
        ui.showStepResult(BUILTIN_COMMANDS[builtinCmd]!);
        ui.showStepDone();
        break;
    }
    return;
  }
  
  const acknowledgment = getIntentAcknowledgment(input);
  ui.showStep(acknowledgment);
  
  try {
    const taskType = detectTaskType(input);
    
    switch (taskType) {
      case 'system':
        await executeSystemTask(input, ctx, ui);
        break;
      case 'search':
        await executeSearchTask(input, ctx, ui);
        break;
      default:
        await executeGeneralTask(input, ctx, ui);
    }
  } catch (error) {
    if (error instanceof Error) {
      if (error.message.includes('timeout') || error.name === 'TimeoutError') {
        ui.showError('è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•');
      } else {
        ui.showError(`å‘ç”Ÿé”™è¯¯: ${error.message}`);
      }
    } else {
      ui.showError('å‘ç”ŸæœªçŸ¥é”™è¯¯');
    }
  }
}

async function main() {
  const program = new Command();
  
  program
    .name('rowbot')
    .description('Windows Desktop AI Agent')
    .version('0.1.0')
    .option('--debug', 'Enable debug mode')
    .option('--tools', 'Enable tool system')
    .parse();

  const options = program.opts();
  const debugMode = options.debug || false;
  const toolsEnabled = options.tools || false;

  const ctx = await initContext();
  
  const ui = new TerminalUI();
  ui.setDebug(debugMode);
  ui.setConfig(ctx.config.provider, ctx.config.model);

  if (toolsEnabled) {
    const toolService = createToolService(ui, {
      workingDirectory: process.cwd(),
    });
    await toolService.initialize();
    ctx.toolService = toolService;
  }

  process.on('exit', () => {
    ui.stop();
  });

  process.on('SIGINT', () => {
    ui.stop();
    process.stdout.write('\nğŸ‘‹ å†è§ï¼\n\n');
    process.exit(0);
  });

  ui.onInput(async (text) => {
    await processInput(text, ctx, ui);
  });

  ui.start();
}

main().catch(console.error);
